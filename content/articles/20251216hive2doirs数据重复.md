---
title: "20251216_周二hive2doirs数据重复的bug"
date: "2025-12-16"
category: "日报"
tags: "日报"
img: ""
priority: "0.7"
changefreq: "weekly"
---
结论，使用TRUNCATE而不是DELETE去删除指定分区的数据。
### 1️⃣ 问题背景

* 你在 Doris 动态分区表中同步 Hive 数据，使用的流程是：

    1. 对指定分区执行 `DELETE FROM table WHERE pt=…` 清空旧数据
    2. 用 Spark `append` 模式写入新数据

* 执行后发现分区中出现重复数据：

  ```sql
  SELECT path, COUNT(*) 
  FROM t b l 
  WHERE pt='2025-12-16' 
  GROUP BY path 
  HAVING COUNT(*) > 1;
  ```

  多条记录的 count > 1，说明同一条 path 被写入了多次。

---

### 2️⃣ 根本原因

1. **DELETE 是行级标记删除**

    * Doris DELETE 只是标记数据为删除状态，不会立即物理删除。
    * 对大分区操作，会生成大量 Delta 文件，清理延迟。

2. **Spark append 写入与 DELETE 并发**

    * append 写入可能在 DELETE 标记尚未完全生效时开始写入。
    * 结果：旧数据 + 新写入数据同时存在 → 导致重复。

3. **DELETE + append 本身不保证覆盖分区**

    * 用 DELETE 模拟覆盖分区，在 Doris 动态分区表中存在 **并发、性能和文件碎片问题**。

---

### 3️⃣ 直接表现

* 分区内部分 path 出现多条记录（重复）
* 查询结果显示 count = 2，说明重复写入
* 大分区 DELETE 性能差、append 写入可能生成更多碎片

---

### 4️⃣ 正确做法

1. **覆盖分区首选 TRUNCATE + append**

    * TRUNCATE 分区会物理清空整个分区数据，性能快、无重复
    * append 写入新数据即可，不需要 DELETE

   ```sql
   TRUNCATE TABLE tbl PARTITION (pt='2025-12-16');
   ```

2. **DELETE + append 仅适合部分行删除**

    * 删除特定条件的数据，而不是整分区
    * 必须确保 DELETE 完全执行，再 append 写入
    * 大分区慎用 DELETE

3. **可选安全措施**

    * 写入前 DataFrame 去重：

      ```scala
      hiveData = hiveData.dropDuplicates("path")
      ```
    * 防止偶发重复

---

### 5️⃣ 总结结论

| 项目   | 描述                                           |
| ---- | -------------------------------------------- |
| 触发条件 | Doris 动态分区表执行 DELETE + Spark append          |
| 根本原因 | DELETE 是行级标记，append 写入与删除并发，MVCC 导致旧数据未被及时清理 |
| 后果   | 分区内数据重复，查询重复 path，性能下降                       |
| 正确方案 | TRUNCATE 分区 + append 写入                      |
| 注意   | DELETE 仅用于部分删除，整分区覆盖要用 TRUNCATE，避免重复和碎片      |

---

💡 **一句话总结**：

> 在 Doris 动态分区表中，“DELETE + append”容易重复写入；如果想覆盖整分区，**用 TRUNCATE + append 才安全高效**。

---
