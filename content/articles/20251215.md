---
title: "20251215_周一_反思"
date: "2025-12-15"
category: "日报"
tags: "日报"
img: ""
priority: "0.7"
changefreq: "weekly"
---

1. 任务阻塞，spark-sql执行日志问题。可以看gemini对话，总结一下问题。
2. 1215周一发现，spark-sql执行的日志捕获线程阻塞吧好像，解决了。
​
 
​## 四、个人待办事项
1. 购买羽绒服
2. 寻找并清洗旧羽绒服（估计找不到）
5. 买菜籽油
- 明天：上线报表任务，讨论热表分析方式
- 下周五：周报讲解报表工作
- 下周：使用新电脑（预计下周到位）
- 下周：关注黄斌值班情况，自己需要值班（据说问题不大），需要问问怎么看问数平台。

2. 实现监控面板，并展示（下周四下班前完成）
3. 进行小文件治理
4. 开畅小文件合并工具学习
5. Grafana仪表盘模板：关注与Hadoop NameNode相关的模板
 
如果你的 Doris 表是一个有历史数据的生产表，并且 hiveData 只是一个分区（或部分数据），使用 Overwrite 将导致 整个表的数据丢失，只剩下 hiveData 的内容。


在 Duplicate 模型下，采用 先 DELETE 后 APPEND 的策略来实现分区级别的覆盖是 完全正确且推荐 的实践方法。
  

### 2. 报表相关工作
- 明天任务上线，主要是生成报表
- 下周五周报需讲解报表工作
- 报表展示内容：小文件排名、存储洞察、冷热温表
- 热表可增加资源提升性能
- 热表分析方式（审计日志还是FS image）待明天讨论
- 计划利用Gemini生成MySQL命令快速制作报表

### 4. 热表访问分析
- 审计日志分析热表访问的实现思路不确定
- 直接查询Doris数据速度快，可用Grafana配置可视化面板
- 不选择Hive或Impala是因为需配置Trino数据源
- 暂时不使用问数平台（学习成本较高）